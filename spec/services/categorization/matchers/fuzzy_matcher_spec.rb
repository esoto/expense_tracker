# frozen_string_literal: true

require "rails_helper"

RSpec.describe Categorization::Matchers::FuzzyMatcher do
  let(:matcher) { described_class.new }

  describe "#match" do
    context "with valid inputs" do
      let(:candidates) do
        [
          { id: 1, text: "Starbucks Coffee" },
          { id: 2, text: "Walmart Supercenter" },
          { id: 3, text: "McDonald's Restaurant" },
          { id: 4, text: "Amazon.com" },
          { id: 5, text: "Target Store" }
        ]
      end

      it "finds exact matches with high confidence" do
        result = matcher.match("starbucks coffee", candidates)

        expect(result).to be_success
        expect(result.best_match[:id]).to eq(1)
        expect(result.best_score).to be >= 0.95
      end

      it "finds partial matches" do
        result = matcher.match("starbucks", candidates)

        expect(result).to be_success
        expect(result.best_match[:id]).to eq(1)
        expect(result.best_score).to be >= 0.70
      end

      it "finds fuzzy matches with typos" do
        result = matcher.match("starbukcs", candidates) # typo

        expect(result).to be_success
        expect(result.best_match[:id]).to eq(1)
        expect(result.best_score).to be >= 0.60
      end

      it "returns empty result for no matches" do
        result = matcher.match("nonexistent merchant", candidates)

        expect(result.matches).to be_empty
      end

      it "handles empty query" do
        result = matcher.match("", candidates)

        expect(result).not_to be_success
        expect(result).to be_empty
      end

      it "handles empty candidates" do
        result = matcher.match("starbucks", [])

        expect(result).not_to be_success
        expect(result).to be_empty
      end

      it "respects max_results option" do
        result = matcher.match("store", candidates, max_results: 2)

        expect(result.matches.size).to be <= 2
      end

      it "respects min_confidence option" do
        result = matcher.match("coffee", candidates, min_confidence: 0.8)

        result.matches.each do |match|
          expect(match[:score]).to be >= 0.8
        end
      end
    end

    context "with Spanish text" do
      let(:spanish_candidates) do
        [
          { id: 1, text: "Caf√© Mar√≠a" },
          { id: 2, text: "Panader√≠a Jos√©" },
          { id: 3, text: "Restaurante El Ni√±o" },
          { id: 4, text: "Supermercado Pe√±a" }
        ]
      end

      it "handles Spanish accents" do
        result = matcher.match("cafe maria", spanish_candidates)

        expect(result).to be_success
        expect(result.best_match[:id]).to eq(1)
      end

      it "normalizes √± character" do
        result = matcher.match("pena", spanish_candidates)

        expect(result).to be_success
        # The match might not be perfect due to the √± character difference
        # Check if we get any match for "Pe√±a"
        if result.best_match
          expect(result.best_match[:text]).to include("Pe√±a")
        end
      end

      it "handles mixed Spanish and English" do
        result = matcher.match("restaurant el nino", spanish_candidates)

        expect(result).to be_success
        expect(result.best_match[:id]).to eq(3)
      end
    end

    context "with different data structures" do
      it "handles string candidates" do
        candidates = [ "Starbucks", "Walmart", "Target" ]
        result = matcher.match("starbucks", candidates)

        expect(result).to be_success
        expect(result.best_match[:text]).to eq("Starbucks")
      end

      it "handles ActiveRecord objects" do
        category = create(:category, name: "Coffee Shops")
        pattern = create(:categorization_pattern,
                        pattern_value: "Starbucks Coffee",
                        category: category)

        result = matcher.match("starbucks", [ pattern ])

        expect(result).to be_success
        expect(result.best_match[:id]).to eq(pattern.id)
      end
    end
  end

  describe "#match_pattern" do
    let(:category) { create(:category, name: "Food & Dining") }
    let(:patterns) do
      [
        create(:categorization_pattern,
               pattern_type: "merchant",
               pattern_value: "Starbucks",
               category: category,
               confidence_weight: 2.0,
               usage_count: 100,
               success_count: 90),
        create(:categorization_pattern,
               pattern_type: "merchant",
               pattern_value: "Coffee Shop",
               category: category,
               confidence_weight: 1.0,
               usage_count: 50,
               success_count: 40)
      ]
    end

    it "matches patterns and includes pattern objects" do
      result = matcher.match_pattern("starbucks coffee", patterns)

      expect(result).to be_success
      expect(result.best_match[:pattern]).to eq(patterns.first)
    end

    it "adjusts scores based on pattern confidence" do
      result = matcher.match_pattern("coffee", patterns)

      result.matches.each do |match|
        expect(match).to have_key(:adjusted_score)
        pattern = patterns.find { |p| p.id == match[:id] }
        expect(match[:adjusted_score]).to be <= match[:score] * pattern.effective_confidence
      end
    end

    it "sorts by adjusted score" do
      result = matcher.match_pattern("shop", patterns)

      if result.matches.size > 1
        scores = result.matches.map { |m| m[:adjusted_score] }
        expect(scores).to eq(scores.sort.reverse)
      end
    end
  end

  describe "#match_merchant" do
    let(:merchants) do
      [
        create(:canonical_merchant,
               name: "starbucks",
               display_name: "Starbucks",
               usage_count: 1000),
        create(:canonical_merchant,
               name: "walmart",
               display_name: "Walmart",
               usage_count: 500),
        create(:canonical_merchant,
               name: "target",
               display_name: "Target",
               usage_count: 100)
      ]
    end

    it "matches merchant names" do
      result = matcher.match_merchant("STARBUCKS COFFEE #123", merchants)

      expect(result).to be_success
      expect(result.best_match[:id]).to eq(merchants.first.id)
    end

    it "boosts popular merchants" do
      # Create two similar merchants with different usage counts
      popular = create(:canonical_merchant,
                      name: "coffee house",
                      usage_count: 1000)
      unpopular = create(:canonical_merchant,
                        name: "coffee home",
                        usage_count: 1)

      result = matcher.match_merchant("coffee", [ popular, unpopular ])

      # Popular merchant should rank higher despite similar base scores
      expect(result.best_match[:id]).to eq(popular.id)
    end

    it "uses merchant normalization" do
      result = matcher.match_merchant("PAYPAL *STARBUCKS", merchants)

      expect(result).to be_success
      expect(result.best_match[:id]).to eq(merchants.first.id)
    end
  end

  describe "#batch_match" do
    let(:candidates) { [ "Starbucks", "Walmart", "Target" ] }
    let(:texts) { [ "starbucks", "walmart", "target" ] }

    it "processes multiple texts" do
      results = matcher.batch_match(texts, candidates)

      expect(results).to be_an(Array)
      expect(results.size).to eq(texts.size)

      results.each do |result|
        expect(result).to be_a(Categorization::Matchers::MatchResult)
      end
    end

    it "handles empty inputs gracefully" do
      expect(matcher.batch_match([], candidates)).to eq([])
      expect(matcher.batch_match(texts, [])).to eq([])
    end
  end

  describe "#calculate_similarity" do
    context "with Jaro-Winkler algorithm" do
      it "returns 1.0 for identical strings" do
        score = matcher.calculate_similarity("starbucks", "starbucks", :jaro_winkler)
        expect(score).to eq(1.0)
      end

      it "returns high score for similar strings" do
        score = matcher.calculate_similarity("starbucks", "starbukcs", :jaro_winkler)
        expect(score).to be >= 0.85
      end

      it "returns low score for different strings" do
        score = matcher.calculate_similarity("starbucks", "walmart", :jaro_winkler)
        # Pure Jaro-Winkler gives ~0.503 for these strings (they share 'ar' and 't')
        expect(score).to be < 0.55
      end

      it "boosts prefix matches" do
        score1 = matcher.calculate_similarity("starbucks", "star", :jaro_winkler)
        score2 = matcher.calculate_similarity("starbucks", "bucks", :jaro_winkler)

        expect(score1).to be > score2
      end
    end

    context "with Levenshtein algorithm" do
      it "returns 1.0 for identical strings" do
        score = matcher.calculate_similarity("coffee", "coffee", :levenshtein)
        expect(score).to eq(1.0)
      end

      it "calculates edit distance correctly" do
        # "cat" to "cut" requires 1 substitution
        score = matcher.calculate_similarity("cat", "cut", :levenshtein)
        expect(score).to be_within(0.01).of(0.667) # 1 - (1/3)
      end

      it "handles insertions and deletions" do
        score = matcher.calculate_similarity("starbucks", "starbuck", :levenshtein)
        expect(score).to be >= 0.88 # 1 deletion out of 9 chars
      end
    end

    context "with Trigram algorithm" do
      it "returns 1.0 for identical strings" do
        score = matcher.calculate_similarity("coffee", "coffee", :trigram)
        expect(score).to eq(1.0)
      end

      it "calculates trigram similarity" do
        score = matcher.calculate_similarity("starbucks", "starbucks coffee", :trigram)
        expect(score).to be > 0.4
        expect(score).to be < 0.8
      end

      it "handles short strings" do
        score = matcher.calculate_similarity("ab", "ab", :trigram)
        expect(score).to be >= 0
      end
    end

    context "with Phonetic algorithm" do
      it "matches phonetically similar words" do
        score = matcher.calculate_similarity("smith", "smyth", :phonetic)
        expect(score).to eq(1.0)
      end

      it "doesn't match phonetically different words" do
        score = matcher.calculate_similarity("coffee", "walmart", :phonetic)
        expect(score).to eq(0.0)
      end
    end
  end

  describe "performance" do
    let(:large_candidate_set) do
      (1..100).map { |i| { id: i, text: "Merchant #{i}" } }
    end

    it "completes matching within reasonable time" do
      start_time = Process.clock_gettime(Process::CLOCK_MONOTONIC)

      matcher.match("Merchant 50", large_candidate_set)

      elapsed_ms = (Process.clock_gettime(Process::CLOCK_MONOTONIC) - start_time) * 1000

      # 100 candidates should complete within 100ms (1ms per candidate average)
      expect(elapsed_ms).to be < 100
    end

    it "uses caching for repeated queries" do
      # First call - cache miss
      result1 = matcher.match("test query", large_candidate_set)

      # Second call - should hit cache
      start_time = Process.clock_gettime(Process::CLOCK_MONOTONIC)
      result2 = matcher.match("test query", large_candidate_set)
      elapsed_ms = (Process.clock_gettime(Process::CLOCK_MONOTONIC) - start_time) * 1000

      expect(result1).to eq(result2)
      expect(elapsed_ms).to be < 1 # Cache hit should be very fast
    end

    it "tracks performance metrics" do
      10.times { |i| matcher.match("query #{i}", large_candidate_set) }

      metrics = matcher.metrics

      expect(metrics[:operations]).to have_key("match")
      expect(metrics[:operations]["match"][:count]).to be >= 10
      expect(metrics[:operations]["match"][:avg_ms]).to be < 10
    end
  end

  describe "text normalization" do
    it "removes noise patterns" do
      candidates = [ { id: 1, text: "Starbucks" } ]

      # Test various noise patterns
      queries = [
        "PAYPAL *STARBUCKS",
        "SQ *STARBUCKS",
        "STARBUCKS INC",
        "STARBUCKS LLC",
        "STARBUCKS #1234",
        "STARBUCKS STORE #5"
      ]

      queries.each do |query|
        result = matcher.match(query, candidates)
        expect(result.best_match[:id]).to eq(1), "Failed to match: #{query}"
      end
    end

    it "handles special characters" do
      candidates = [ { id: 1, text: "AT&T Store" } ]

      result = matcher.match("AT&T", candidates)
      expect(result).to be_success
    end

    it "handles mixed case" do
      candidates = [ { id: 1, text: "McDonald's" } ]

      queries = [ "MCDONALD'S", "mcdonalds", "McDonald's", "MCDONALDS" ]

      queries.each do |query|
        result = matcher.match(query, candidates)
        expect(result).to be_success
      end
    end
  end

  describe "#clear_cache" do
    it "clears the cache" do
      # Populate cache
      candidates = [ "test" ]
      matcher.match("query1", candidates)
      matcher.match("query2", candidates)

      # Clear cache
      matcher.clear_cache

      # Verify cache was cleared by checking metrics
      # (implementation depends on how cache tracks its state)
      expect { matcher.clear_cache }.not_to raise_error
    end
  end

  describe "edge cases" do
    it "handles nil values" do
      expect(matcher.match(nil, [ "test" ])).to be_empty
      expect(matcher.match("test", nil)).to be_empty
    end

    it "handles very long strings" do
      long_text = "a" * 1000
      candidates = [ { text: long_text } ]

      result = matcher.match(long_text, candidates)
      expect(result).to be_success
    end

    it "handles Unicode characters" do
      candidates = [
        { id: 1, text: "Caf√© ‚òï" },
        { id: 2, text: "Sushi üç£" },
        { id: 3, text: "Pizza üçï" }
      ]

      result = matcher.match("cafe", candidates)
      expect(result).to be_success
      expect(result.best_match[:id]).to eq(1)
    end

    it "handles empty strings in candidates" do
      candidates = [
        { id: 1, text: "" },
        { id: 2, text: "Starbucks" },
        { id: 3, text: nil }
      ]

      result = matcher.match("starbucks", candidates)
      expect(result).to be_success
      expect(result.best_match[:id]).to eq(2)
    end
  end

  describe "configuration options" do
    it "uses specified algorithms" do
      custom_matcher = described_class.new(algorithms: [ :levenshtein ])

      result = custom_matcher.match("starbucks", [ "starbucks" ])

      expect(result.algorithm_used).to eq([ :levenshtein ])
    end

    it "disables caching when configured" do
      no_cache_matcher = described_class.new(enable_caching: false)

      candidates = [ "test" ]
      result1 = no_cache_matcher.match("query", candidates)
      result2 = no_cache_matcher.match("query", candidates)

      # Without cache, both calls should take similar time
      expect(result1).to eq(result2)
    end

    it "disables text normalization when configured" do
      no_norm_matcher = described_class.new(normalize_text: false)

      result = no_norm_matcher.match("STARBUCKS", [ "starbucks" ])

      # Without normalization, case-sensitive match should fail
      expect(result.best_score).to be < 1.0
    end
  end
end
